{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "from general_functions import create_balanced_dataset\n",
    "\n",
    "file = open(\"dataset/zone_4.pickle\", \"rb\")\n",
    "zone_4 = pickle.load(file)\n",
    "file = None\n",
    "\n",
    "file = open(\"dataset/zone_7.pickle\", \"rb\")\n",
    "zone_7 = pickle.load(file)\n",
    "file = None\n",
    "\n",
    "# zone_7_resampled = create_balanced_dataset([\"dataset/zone_7.pickle\"])\n",
    "\n",
    "# with open(\"dataset/zone_7_resampled.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(zone_7_resampled, file)\n",
    "\n",
    "# zone_4_resampled = create_balanced_dataset([\"dataset/zone_4.pickle\"])\n",
    "\n",
    "# with open(\"dataset/zone_4_resampled.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(zone_4_resampled, file)\n",
    "\n",
    "with open(\"dataset/zone_4_resampled.pickle\", \"rb\") as file:\n",
    "    zone_4_resampled = pickle.load(file)\n",
    "\n",
    "with open(\"dataset/zone_7_resampled.pickle\", \"rb\") as file:\n",
    "    zone_7_resampled = pickle.load(file)\n",
    "    \n",
    "experiment_arr = [(zone_4_resampled, zone_7), (zone_7_resampled, zone_4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_features = ['impundment_mean_3', 'hpmf_median_4', 'impundment_mean_4', 'impundment_mean_2', 'impundment_median_4', 'slope_non_ditch', 'impundment_std_4', 'impoundment_amplified_no_streams', 'skyview_gabor', 'impundment_amplified', 'skyview_max_6', 'skyview_non_ditch', 'hpmf_min_2', 'impundment_median_2', 'hpmf_min_6', 'hpmf_min_4', 'hpmf_mean_4', 'impundment_mean_6', 'skyview_max_4', 'impundment_max_6', 'slope_mean_6', 'slope_std_6', 'skyview_gabor_no_streams', 'hpmf_filter_no_streams', 'hpmf_median_2', 'skyview_median_6', 'slope_median_6', 'hpmf_median_6', 'impundment_std_6', 'skyview_mean_6', 'hpmf_mean_6', 'slope_min_6', 'hpmf_filter', 'skyview_std_6', 'skyview_min_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_function(learning_rate=.1,\n",
    "                   n_estimators=100,\n",
    "                   max_depth=5,\n",
    "                   min_child_weight=1,\n",
    "                   gamma=0,\n",
    "                   subsample=.8,\n",
    "                   colsample_bytree=.8,\n",
    "                   scale_pos_weight=2,\n",
    "                   reg_alpha=0,\n",
    "                   reg_lambda=0):\n",
    "    \n",
    "    max_depth = int(max_depth)\n",
    "    min_child_weight = int(min_child_weight)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    y_test_all = np.zeros((2, len(experiment_arr[0][1]))).astype(np.int8)\n",
    "    pred_all = np.zeros((2, len(experiment_arr[0][1]))).astype(np.int8)\n",
    "    \n",
    "    for i, (training_dataset, test_dataset) in enumerate(experiment_arr):\n",
    "        X_train = np.array(training_dataset.filter(items=most_important_features).loc[:, training_dataset.filter(items=most_important_features).columns != \"label_3m\"]).astype(np.float32)\n",
    "        y_train = np.array(training_dataset[\"label_3m\"]).astype(np.int8)\n",
    "        \n",
    "        training_dataset = None\n",
    "        gc.collect()\n",
    "        \n",
    "        X_test = np.array(test_dataset.filter(items=most_important_features).loc[:, test_dataset.filter(items=most_important_features).columns != \"label_3m\"]).astype(np.float32)\n",
    "        y_test = np.array(test_dataset[\"label_3m\"]).astype(np.int8)\n",
    "        \n",
    "        test_dataset = None\n",
    "        gc.collect()\n",
    "        \n",
    "        clf = xgboost.sklearn.XGBClassifier(max_depth=int(max_depth),\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            n_estimators=n_estimators,\n",
    "                                            gamma=gamma,\n",
    "                                            min_child_weight=int(min_child_weight),\n",
    "                                            subsample=subsample,\n",
    "                                            colsample_bytree=colsample_bytree,\n",
    "                                            scale_pos_weight=scale_pos_weight,\n",
    "                                            reg_alpha=reg_alpha,\n",
    "                                            reg_lambda=reg_lambda,\n",
    "                                            seed=41,\n",
    "                                            gpu_id=0,\n",
    "                                            **{\"predictor\": \"gpu_predictor\"}\n",
    "                                           )\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        pred = np.array(pred).astype(np.int8)\n",
    "        y_test = np.array(y_test).astype(np.int8)\n",
    "        \n",
    "        pred_all[i] = pred\n",
    "        y_test_all[i] = y_test\n",
    "        \n",
    "    pred_all = pred_all.reshape(-1)\n",
    "    y_test_all = y_test_all.reshape(-1)\n",
    "    \n",
    "    kappa = cohen_kappa_score(np.array(y_test_all), np.array(pred_all))\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt.logger import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "\n",
    "pbounds = {\"learning_rate\": (1e-4, 1e0),\n",
    "           \"n_estimators\": (50.0, 500.0),\n",
    "           \"gamma\": (0.0, 1.0),\n",
    "           \"min_child_weight\": (1e-3, 30.0),\n",
    "           \"subsample\": (.2, 1.0),\n",
    "           \"colsample_bytree\": (.2, 1.0),\n",
    "           \"scale_pos_weight\": (1.0, 4.0),\n",
    "           \"max_depth\": (3.0, 30),\n",
    "           \"reg_alpha\": (0.0, 1e-1),\n",
    "           \"reg_lambda\": (0.0, 1e-1)\n",
    "          }\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=optim_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "optimizer.probe(\n",
    "    params={\"learning_rate\": 0.3135,\n",
    "           \"n_estimators\": 452,\n",
    "           \"gamma\": 0.9683,\n",
    "           \"min_child_weight\": 26.29,\n",
    "           \"subsample\": 0.9025,\n",
    "           \"colsample_bytree\": 0.8406,\n",
    "           \"scale_pos_weight\": 1.509,\n",
    "           \"max_depth\": 21,\n",
    "           \"reg_alpha\": 0.008504,\n",
    "           \"reg_lambda\": 0.003905\n",
    "          },\n",
    "    lazy=True,\n",
    ")\n",
    "\n",
    "#from bayes_opt.util import load_logs\n",
    "#load_logs(optimizer, logs=[\"./xgboost_log.json\"]);\n",
    "\n",
    "#logger = JSONLogger(path=\"./xgboost_log.json\")\n",
    "#optimizer.subscribe(Events.OPTIMIZATION_STEP, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | scale_... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4133  \u001b[0m | \u001b[0m 0.8406  \u001b[0m | \u001b[0m 0.9683  \u001b[0m | \u001b[0m 0.3135  \u001b[0m | \u001b[0m 21.0    \u001b[0m | \u001b[0m 26.29   \u001b[0m | \u001b[0m 452.0   \u001b[0m | \u001b[0m 0.008504\u001b[0m | \u001b[0m 0.003905\u001b[0m | \u001b[0m 1.509   \u001b[0m | \u001b[0m 0.9025  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.2364  \u001b[0m | \u001b[0m 0.5336  \u001b[0m | \u001b[0m 0.7203  \u001b[0m | \u001b[0m 0.000214\u001b[0m | \u001b[0m 11.16   \u001b[0m | \u001b[0m 4.404   \u001b[0m | \u001b[0m 91.55   \u001b[0m | \u001b[0m 0.01863 \u001b[0m | \u001b[0m 0.03456 \u001b[0m | \u001b[0m 2.19    \u001b[0m | \u001b[0m 0.6311  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.4181  \u001b[0m | \u001b[95m 0.5354  \u001b[0m | \u001b[95m 0.6852  \u001b[0m | \u001b[95m 0.2045  \u001b[0m | \u001b[95m 26.71   \u001b[0m | \u001b[95m 0.8226  \u001b[0m | \u001b[95m 351.7   \u001b[0m | \u001b[95m 0.04173 \u001b[0m | \u001b[95m 0.05587 \u001b[0m | \u001b[95m 1.421   \u001b[0m | \u001b[95m 0.3585  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4089  \u001b[0m | \u001b[0m 0.8406  \u001b[0m | \u001b[0m 0.9683  \u001b[0m | \u001b[0m 0.3135  \u001b[0m | \u001b[0m 21.69   \u001b[0m | \u001b[0m 26.29   \u001b[0m | \u001b[0m 452.6   \u001b[0m | \u001b[0m 0.008504\u001b[0m | \u001b[0m 0.003905\u001b[0m | \u001b[0m 1.509   \u001b[0m | \u001b[0m 0.9025  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3553  \u001b[0m | \u001b[0m 0.2787  \u001b[0m | \u001b[0m 0.4211  \u001b[0m | \u001b[0m 0.9579  \u001b[0m | \u001b[0m 17.4    \u001b[0m | \u001b[0m 20.76   \u001b[0m | \u001b[0m 192.0   \u001b[0m | \u001b[0m 0.06865 \u001b[0m | \u001b[0m 0.08346 \u001b[0m | \u001b[0m 1.055   \u001b[0m | \u001b[0m 0.8001  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3815  \u001b[0m | \u001b[0m 0.9911  \u001b[0m | \u001b[0m 0.7482  \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 24.31   \u001b[0m | \u001b[0m 3.098   \u001b[0m | \u001b[0m 251.6   \u001b[0m | \u001b[0m 0.09086 \u001b[0m | \u001b[0m 0.02936 \u001b[0m | \u001b[0m 1.863   \u001b[0m | \u001b[0m 0.304   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2422  \u001b[0m | \u001b[0m 0.5851  \u001b[0m | \u001b[0m 0.3683  \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 3.04    \u001b[0m | \u001b[0m 29.51   \u001b[0m | \u001b[0m 343.0   \u001b[0m | \u001b[0m 0.01009 \u001b[0m | \u001b[0m 0.07553 \u001b[0m | \u001b[0m 3.292   \u001b[0m | \u001b[0m 0.331   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.2615  \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 0.8815  \u001b[0m | \u001b[0m 0.4359  \u001b[0m | \u001b[0m 3.093   \u001b[0m | \u001b[0m 2.023   \u001b[0m | \u001b[0m 498.4   \u001b[0m | \u001b[0m 0.07717 \u001b[0m | \u001b[0m 0.07737 \u001b[0m | \u001b[0m 3.089   \u001b[0m | \u001b[0m 0.5449  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.3574  \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3096  \u001b[0m | \u001b[0m 0.7885  \u001b[0m | \u001b[0m 0.1914  \u001b[0m | \u001b[0m 0.5151  \u001b[0m | \u001b[0m 3.197   \u001b[0m | \u001b[0m 0.547   \u001b[0m | \u001b[0m 422.3   \u001b[0m | \u001b[0m 0.02093 \u001b[0m | \u001b[0m 0.02865 \u001b[0m | \u001b[0m 1.542   \u001b[0m | \u001b[0m 0.6142  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.247   \u001b[0m | \u001b[0m 0.4675  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 128.8   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.000958\u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.3861  \u001b[0m | \u001b[0m 0.9537  \u001b[0m | \u001b[0m 0.1371  \u001b[0m | \u001b[0m 0.1076  \u001b[0m | \u001b[0m 29.5    \u001b[0m | \u001b[0m 29.74   \u001b[0m | \u001b[0m 386.0   \u001b[0m | \u001b[0m 0.07235 \u001b[0m | \u001b[0m 0.01426 \u001b[0m | \u001b[0m 3.254   \u001b[0m | \u001b[0m 0.4611  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.3545  \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.779   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.2976  \u001b[0m | \u001b[0m 0.5171  \u001b[0m | \u001b[0m 0.07205 \u001b[0m | \u001b[0m 0.9566  \u001b[0m | \u001b[0m 5.051   \u001b[0m | \u001b[0m 28.86   \u001b[0m | \u001b[0m 489.3   \u001b[0m | \u001b[0m 0.03675 \u001b[0m | \u001b[0m 0.08305 \u001b[0m | \u001b[0m 3.41    \u001b[0m | \u001b[0m 0.749   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 0.2332  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 268.1   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.005353\u001b[0m | \u001b[0m 3.568   \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9368  \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 184.4   \u001b[0m | \u001b[0m 5.823e-0\u001b[0m | \u001b[0m 0.0908  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.1978  \u001b[0m | \u001b[0m 0.8931  \u001b[0m | \u001b[0m 0.7508  \u001b[0m | \u001b[0m 0.9952  \u001b[0m | \u001b[0m 3.347   \u001b[0m | \u001b[0m 0.6072  \u001b[0m | \u001b[0m 215.1   \u001b[0m | \u001b[0m 0.04619 \u001b[0m | \u001b[0m 0.08016 \u001b[0m | \u001b[0m 3.138   \u001b[0m | \u001b[0m 0.4511  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.2895  \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.2657  \u001b[0m | \u001b[0m 0.8891  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 293.1   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.2727  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 153.3   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.2315  \u001b[0m | \u001b[0m 0.5846  \u001b[0m | \u001b[0m 0.08412 \u001b[0m | \u001b[0m 0.5853  \u001b[0m | \u001b[0m 3.529   \u001b[0m | \u001b[0m 29.95   \u001b[0m | \u001b[0m 410.1   \u001b[0m | \u001b[0m 0.06172 \u001b[0m | \u001b[0m 0.01453 \u001b[0m | \u001b[0m 3.455   \u001b[0m | \u001b[0m 0.2136  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (1.0, 0.0, 1.0, 30.0, 0.001, 313.8429809158289, 3.857736253772469e-08, 0.1, 1.0, 1.0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fcbab9d84ee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-156416529011>\u001b[0m in \u001b[0;36moptim_function\u001b[1;34m(learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, scale_pos_weight, reg_alpha, reg_lambda)\u001b[0m\n\u001b[0;32m     45\u001b[0m                                            )\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    815\u001b[0m                                 missing=self.missing, nthread=self.n_jobs)\n\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[0;32m    818\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    206\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.maximize(n_iter=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.41814894011216863,\n",
       " 'params': {'colsample_bytree': 0.5353556115226359,\n",
       "  'gamma': 0.6852195003967595,\n",
       "  'learning_rate': 0.20453180450654426,\n",
       "  'max_depth': 26.709170782555525,\n",
       "  'min_child_weight': 0.8226004083445869,\n",
       "  'n_estimators': 351.710379580281,\n",
       "  'reg_alpha': 0.0417304802367127,\n",
       "  'reg_lambda': 0.05586898284457517,\n",
       "  'scale_pos_weight': 1.4211608157857012,\n",
       "  'subsample': 0.35848119126790307}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
