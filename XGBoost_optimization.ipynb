{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gc\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "from general_functions import create_balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"dataset/zone_4.pickle\", \"rb\")\n",
    "zone_4 = pickle.load(file)\n",
    "file = None\n",
    "\n",
    "file = open(\"dataset/zone_7.pickle\", \"rb\")\n",
    "zone_7 = pickle.load(file)\n",
    "file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zone_7_resampled = create_balanced_dataset([\"dataset/zone_7.pickle\"])\n",
    "\n",
    "# with open(\"dataset/zone_7_resampled.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(zone_7_resampled, file)\n",
    "\n",
    "# zone_4_resampled = create_balanced_dataset([\"dataset/zone_4.pickle\"])\n",
    "\n",
    "# with open(\"dataset/zone_4_resampled.pickle\", \"wb\") as file:\n",
    "#     pickle.dump(zone_4_resampled, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/zone_4_resampled.pickle\", \"rb\") as file:\n",
    "    zone_4_resampled = pickle.load(file)\n",
    "\n",
    "with open(\"dataset/zone_7_resampled.pickle\", \"rb\") as file:\n",
    "    zone_7_resampled = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_arr = [(zone_4_resampled, zone_7), (zone_7_resampled, zone_4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"dataset/zone_4.pickle\", \"rb\")\n",
    "train_data = pickle.load(file)\n",
    "\n",
    "file = open(\"dataset/zone_7.pickle\", \"rb\")\n",
    "test_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = np.array(train_data.loc[:, train_data.columns != 'label_3m']), np.array(train_data[\"label_3m\"]).astype(int)\n",
    "train_data = None\n",
    "\n",
    "X_test, y_test = np.array(test_data.loc[:, test_data.columns != 'label_3m']), np.array(test_data[\"label_3m\"]).astype(int)\n",
    "test_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization to determine parameters for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_function(learning_rate=.1,\n",
    "                   n_estimators=100,\n",
    "                   max_depth=5,\n",
    "                   min_child_weight=1,\n",
    "                   gamma=0,\n",
    "                   subsample=.8,\n",
    "                   colsample_bytree=.8,\n",
    "                   scale_pos_weight=2,\n",
    "                   reg_alpha=0):\n",
    "    \n",
    "    max_depth = int(max_depth)\n",
    "    min_child_weight = int(min_child_weight)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    clf = xgboost.dask.DaskXGBClassifier(max_depth=int(max_depth),\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        gamma=gamma,\n",
    "                                        min_child_weight=int(min_child_weight),\n",
    "                                        subsample=subsample,\n",
    "                                        colsample_bytree=colsample_bytree,\n",
    "                                        scale_pos_weight=scale_pos_weight,\n",
    "                                        reg_alpha=reg_alpha,\n",
    "                                        n_jobs=4,\n",
    "                                        tree_method=\"gpu_hist\",\n",
    "                                        seed=41,\n",
    "                                        gpu_id=0\n",
    "                                       )\n",
    "    \n",
    "    clf.fit(X_train[:, most_important_features], y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test[:, most_important_features])\n",
    "    kappa = cohen_kappa_score(y_test, pred)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BayesianOptimization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7a6c800486c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m           }\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m optimizer = BayesianOptimization(\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptim_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BayesianOptimization' is not defined"
     ]
    }
   ],
   "source": [
    "pbounds = {\"learning_rate\": (1e-4, 1e0),\n",
    "           \"n_estimators\": (50, 500),\n",
    "           \"gamma\": (0, .9),\n",
    "           \"min_child_weight\": (0, 10),\n",
    "           \"subsample\": (.1, .95),\n",
    "           \"colsample_bytree\": (.1, .95),\n",
    "           \"scale_pos_weight\": (1, 5),\n",
    "           \"max_depth\": (3, 15),\n",
    "           \"reg_alpha\": (0, 1e-3)\n",
    "          }\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=optim_function,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | scale_... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4422  \u001b[0m | \u001b[0m 0.4545  \u001b[0m | \u001b[0m 0.6483  \u001b[0m | \u001b[0m 0.000214\u001b[0m | \u001b[0m 6.628   \u001b[0m | \u001b[0m 1.468   \u001b[0m | \u001b[0m 91.55   \u001b[0m | \u001b[0m 0.000186\u001b[0m | \u001b[0m 2.382   \u001b[0m | \u001b[0m 0.4373  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.481   \u001b[0m | \u001b[95m 0.558   \u001b[0m | \u001b[95m 0.3773  \u001b[0m | \u001b[95m 0.6853  \u001b[0m | \u001b[95m 5.453   \u001b[0m | \u001b[95m 8.781   \u001b[0m | \u001b[95m 62.32   \u001b[0m | \u001b[95m 0.000670\u001b[0m | \u001b[95m 2.669   \u001b[0m | \u001b[95m 0.5749  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3576  \u001b[0m | \u001b[0m 0.2193  \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 0.8008  \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 3.134   \u001b[0m | \u001b[0m 361.5   \u001b[0m | \u001b[0m 0.000876\u001b[0m | \u001b[0m 4.578   \u001b[0m | \u001b[0m 0.1723  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4776  \u001b[0m | \u001b[0m 0.1332  \u001b[0m | \u001b[0m 0.1528  \u001b[0m | \u001b[0m 0.8782  \u001b[0m | \u001b[0m 4.18    \u001b[0m | \u001b[0m 4.211   \u001b[0m | \u001b[0m 481.1   \u001b[0m | \u001b[0m 0.000533\u001b[0m | \u001b[0m 3.768   \u001b[0m | \u001b[0m 0.3682  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.4978  \u001b[0m | \u001b[95m 0.6835  \u001b[0m | \u001b[95m 0.7512  \u001b[0m | \u001b[95m 0.01839 \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 9.889   \u001b[0m | \u001b[95m 386.7   \u001b[0m | \u001b[95m 0.000280\u001b[0m | \u001b[95m 4.157   \u001b[0m | \u001b[95m 0.1877  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.3422  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 206.9   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4139  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 440.8   \u001b[0m | \u001b[0m 0.000214\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.4397  \u001b[0m | \u001b[0m 0.5121  \u001b[0m | \u001b[0m 0.4732  \u001b[0m | \u001b[0m 0.5616  \u001b[0m | \u001b[0m 10.17   \u001b[0m | \u001b[0m 8.951   \u001b[0m | \u001b[0m 386.5   \u001b[0m | \u001b[0m 0.000545\u001b[0m | \u001b[0m 2.082   \u001b[0m | \u001b[0m 0.6307  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.4902  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 274.8   \u001b[0m | \u001b[0m 5.052e-1\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.4126  \u001b[0m | \u001b[0m 0.6884  \u001b[0m | \u001b[0m 0.5291  \u001b[0m | \u001b[0m 0.5267  \u001b[0m | \u001b[0m 13.34   \u001b[0m | \u001b[0m 8.947   \u001b[0m | \u001b[0m 499.8   \u001b[0m | \u001b[0m 0.000680\u001b[0m | \u001b[0m 4.032   \u001b[0m | \u001b[0m 0.2276  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4635  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 146.8   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.4615  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.3909  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3906  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 415.9   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.381   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 85.95   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.5005  \u001b[0m | \u001b[95m 0.9126  \u001b[0m | \u001b[95m 0.4131  \u001b[0m | \u001b[95m 0.2495  \u001b[0m | \u001b[95m 3.27    \u001b[0m | \u001b[95m 0.348   \u001b[0m | \u001b[95m 155.7   \u001b[0m | \u001b[95m 0.000689\u001b[0m | \u001b[95m 4.196   \u001b[0m | \u001b[95m 0.427   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3198  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 182.5   \u001b[0m | \u001b[0m 0.000634\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4325  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.000419\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.3476  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 259.6   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.4848  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 474.9   \u001b[0m | \u001b[0m 0.000826\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.3836  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.3425  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.4095  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 159.0   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.4023  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 131.8   \u001b[0m | \u001b[0m 0.000517\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.4879  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 240.5   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.4383  \u001b[0m | \u001b[0m 0.6061  \u001b[0m | \u001b[0m 0.5987  \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 14.63   \u001b[0m | \u001b[0m 1.812   \u001b[0m | \u001b[0m 400.9   \u001b[0m | \u001b[0m 0.000275\u001b[0m | \u001b[0m 4.926   \u001b[0m | \u001b[0m 0.6198  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.4765  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 256.1   \u001b[0m | \u001b[0m 0.000503\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.405   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.4068  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 67.64   \u001b[0m | \u001b[0m 7.765e-1\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.4772  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 469.4   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.4775  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 322.0   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5004  \u001b[0m | \u001b[0m 0.5257  \u001b[0m | \u001b[0m 0.736   \u001b[0m | \u001b[0m 0.09155 \u001b[0m | \u001b[0m 3.765   \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 455.4   \u001b[0m | \u001b[0m 0.000964\u001b[0m | \u001b[0m 4.793   \u001b[0m | \u001b[0m 0.7859  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.4737  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 138.8   \u001b[0m | \u001b[0m 0.000690\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.4876  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 78.41   \u001b[0m | \u001b[0m 0.000400\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.3857  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 229.5   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.04805 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 298.7   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.4961  \u001b[0m | \u001b[0m 0.4063  \u001b[0m | \u001b[0m 0.4947  \u001b[0m | \u001b[0m 0.3888  \u001b[0m | \u001b[0m 4.016   \u001b[0m | \u001b[0m 9.798   \u001b[0m | \u001b[0m 343.0   \u001b[0m | \u001b[0m 0.000706\u001b[0m | \u001b[0m 4.728   \u001b[0m | \u001b[0m 0.4068  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.3806  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 259.0   \u001b[0m | \u001b[0m 0.000911\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.3909  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 329.1   \u001b[0m | \u001b[0m 1.192e-0\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.49    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 339.1   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.4318  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 375.9   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.3915  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 460.1   \u001b[0m | \u001b[0m 0.000334\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.3138  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 436.2   \u001b[0m | \u001b[0m 0.000739\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.4087  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 466.6   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.49    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 217.2   \u001b[0m | \u001b[0m 0.000964\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.4665  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 328.4   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.4323  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 275.5   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.4162  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 156.4   \u001b[0m | \u001b[0m 0.000993\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.4177  \u001b[0m | \u001b[0m 0.5349  \u001b[0m | \u001b[0m 0.4455  \u001b[0m | \u001b[0m 0.6843  \u001b[0m | \u001b[0m 14.93   \u001b[0m | \u001b[0m 9.437   \u001b[0m | \u001b[0m 406.4   \u001b[0m | \u001b[0m 0.000904\u001b[0m | \u001b[0m 4.3     \u001b[0m | \u001b[0m 0.649   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 490.6   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.4072  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 100.7   \u001b[0m | \u001b[0m 1.454e-0\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.4141  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 484.9   \u001b[0m | \u001b[0m 1.654e-1\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.4873  \u001b[0m | \u001b[0m 0.58    \u001b[0m | \u001b[0m 0.4729  \u001b[0m | \u001b[0m 0.8085  \u001b[0m | \u001b[0m 3.189   \u001b[0m | \u001b[0m 0.06146 \u001b[0m | \u001b[0m 103.6   \u001b[0m | \u001b[0m 0.000605\u001b[0m | \u001b[0m 4.883   \u001b[0m | \u001b[0m 0.6951  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.3925  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 261.0   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.462   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 232.2   \u001b[0m | \u001b[0m 3.7e-05 \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.3892  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 390.5   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.4322  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 175.4   \u001b[0m | \u001b[0m 7.104e-1\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.3995  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 227.8   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.4317  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 482.4   \u001b[0m | \u001b[0m 3.012e-1\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.467   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 278.6   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.4091  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 441.7   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.3794  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 71.69   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.4661  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 494.6   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.2941  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 456.3   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.3876  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 110.1   \u001b[0m | \u001b[0m 9.449e-0\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.4775  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 437.7   \u001b[0m | \u001b[0m 0.000981\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.4879  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 195.8   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 61.64   \u001b[0m | \u001b[0m 3.052e-1\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.4896  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 166.2   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.4142  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 376.6   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.4322  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 149.5   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.4655  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 482.0   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.4167  \u001b[0m | \u001b[0m 0.6799  \u001b[0m | \u001b[0m 0.4133  \u001b[0m | \u001b[0m 0.7547  \u001b[0m | \u001b[0m 3.336   \u001b[0m | \u001b[0m 0.1605  \u001b[0m | \u001b[0m 119.1   \u001b[0m | \u001b[0m 9.805e-0\u001b[0m | \u001b[0m 1.091   \u001b[0m | \u001b[0m 0.2413  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.4849  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 279.4   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.4871  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 5.651e-0\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.485   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 384.7   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.488   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 427.0   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.4318  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 353.7   \u001b[0m | \u001b[0m 3.15e-08\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.3917  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 355.8   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.4179  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 337.7   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.4325  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 244.8   \u001b[0m | \u001b[0m 2.579e-1\u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.467   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 195.9   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.3953  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 9.124   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 332.4   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.2976  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 151.3   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.3848  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 313.1   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.3483  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 145.3   \u001b[0m | \u001b[0m 0.000109\u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.3936  \u001b[0m | \u001b[0m 0.9267  \u001b[0m | \u001b[0m 0.3652  \u001b[0m | \u001b[0m 0.02097 \u001b[0m | \u001b[0m 3.581   \u001b[0m | \u001b[0m 0.3363  \u001b[0m | \u001b[0m 170.9   \u001b[0m | \u001b[0m 0.000998\u001b[0m | \u001b[0m 1.056   \u001b[0m | \u001b[0m 0.2381  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.95, 0.0, 1.0, 15.0, 0.0, 208.6965126936294, 0.0, 5.0, 0.95)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4f6b9349beb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-67a4b3c3ad9f>\u001b[0m in \u001b[0;36moptim_function\u001b[1;34m(learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, scale_pos_weight, reg_alpha)\u001b[0m\n\u001b[0;32m     28\u001b[0m                                        )\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_important_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_important_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    815\u001b[0m                                 missing=self.missing, nthread=self.n_jobs)\n\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[0;32m    818\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    206\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\program\\anaconda\\envs\\torch\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer.maximize(n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.5004687061446937,\n",
       " 'params': {'colsample_bytree': 0.9125598867458771,\n",
       "  'gamma': 0.41309970007591623,\n",
       "  'learning_rate': 0.2495446719246513,\n",
       "  'max_depth': 3.27021719586084,\n",
       "  'min_child_weight': 0.34796142621455917,\n",
       "  'n_estimators': 155.73578545537174,\n",
       "  'reg_alpha': 0.0006891651003411668,\n",
       "  'scale_pos_weight': 4.1957470427759915,\n",
       "  'subsample': 0.42699958983347897}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_function(learning_rate=.1,\n",
    "                   n_estimators=100,\n",
    "                   max_depth=5,\n",
    "                   min_child_weight=1,\n",
    "                   gamma=0,\n",
    "                   subsample=.8,\n",
    "                   colsample_bytree=.8,\n",
    "                   scale_pos_weight=2,\n",
    "                   reg_alpha=0):\n",
    "    \n",
    "    max_depth = int(max_depth)\n",
    "    min_child_weight = int(min_child_weight)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    clf = xgboost.sklearn.XGBClassifier(max_depth=int(max_depth),\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        n_estimators=n_estimators,\n",
    "                                        gamma=gamma,\n",
    "                                        min_child_weight=int(min_child_weight),\n",
    "                                        subsample=subsample,\n",
    "                                        colsample_bytree=colsample_bytree,\n",
    "                                        scale_pos_weight=scale_pos_weight,\n",
    "                                        reg_alpha=reg_alpha,\n",
    "                                        n_jobs=4,\n",
    "                                        tree_method=\"gpu_hist\",\n",
    "                                        seed=41\n",
    "                                       )\n",
    "    \n",
    "    clf.fit(X_train[:, most_important_features], y_train)\n",
    "    \n",
    "    pred = clf.predict(X_test[:, most_important_features])\n",
    "    kappa = cohen_kappa_score(y_test, pred)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Extreme Gradient Boosting performance for different feature spaces\n",
    "## Features to use based on feature importance from previous iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used in experiment:\n",
      "['hpmf_raw', 'skyview_raw', 'impundment_raw', 'slope_raw', 'DEM_ditch_detection', 'DEM_ditch_detection_no_streams', 'conic_mean', 'skyview_non_ditch', 'skyview_gabor', 'conic_mean_no_streams', 'skyview_gabor_no_streams', 'skyview_mean_2', 'skyview_mean_3', 'skyview_mean_4', 'skyview_mean_6', 'skyview_median_2', 'skyview_median_4', 'skyview_median_6', 'skyview_min_2', 'skyview_min_4', 'skyview_min_6', 'skyview_max_2', 'skyview_max_4', 'skyview_max_6', 'skyview_std_2', 'skyview_std_4', 'skyview_std_6', 'impundment_amplified', 'impoundment_amplified_no_streams', 'impundment_mean_2', 'impundment_mean_3', 'impundment_mean_4', 'impundment_mean_6', 'impundment_median_2', 'impundment_median_4', 'impundment_median_6', 'impundment_min_2', 'impundment_min_4', 'impundment_min_6', 'impundment_max_2', 'impundment_max_4', 'impundment_max_6', 'impundment_std_2', 'impundment_std_4', 'impundment_std_6', 'hpmf_filter', 'hpmf_gabor', 'hpmf_gabor_no_streams', 'hpmf_filter_no_streams', 'hpmf_mean_2', 'hpmf_mean_3', 'hpmf_mean_4', 'hpmf_mean_6', 'hpmf_median_2', 'hpmf_median_4', 'hpmf_median_6', 'hpmf_min_2', 'hpmf_min_4', 'hpmf_min_6', 'hpmf_max_2', 'hpmf_max_4', 'hpmf_max_6', 'hpmf_std_2', 'hpmf_std_4', 'hpmf_std_6', 'slope_non_ditch', 'slope_mean_2', 'slope_mean_3', 'slope_mean_4', 'slope_mean_6', 'slope_median_2', 'slope_median_4', 'slope_median_6', 'slope_min_2', 'slope_min_4', 'slope_min_6', 'slope_max_2', 'slope_max_4', 'slope_std_2', 'slope_std_4', 'slope_std_6']\n",
      "\n",
      "\n",
      "Amount of features X_train: 81, X_test: 81\n",
      "Amount of features X_train: 81, X_test: 81\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.33971627056598663\n",
      "hpmf_mean_4  -  0.08296303264796734\n",
      "hpmf_median_4  -  0.07762619480490685\n",
      "DEM_ditch_detection_no_streams  -  0.060605392791330814\n",
      "hpmf_min_2  -  0.04759785905480385\n",
      "impundment_mean_4  -  0.04054585471749306\n",
      "impundment_median_4  -  0.035806921077892184\n",
      "impundment_mean_2  -  0.028956038877367973\n",
      "hpmf_gabor  -  0.016875661443918943\n",
      "skyview_gabor  -  0.01488265348598361\n",
      "hpmf_min_4  -  0.011895457515493035\n",
      "slope_non_ditch  -  0.011702224612236023\n",
      "impundment_median_2  -  0.010264626936987042\n",
      "skyview_gabor_no_streams  -  0.009789136471226811\n",
      "impundment_amplified  -  0.00885273888707161\n",
      "hpmf_median_6  -  0.008244501193985343\n",
      "hpmf_mean_6  -  0.007412270992062986\n",
      "skyview_non_ditch  -  0.006923730485141277\n",
      "hpmf_median_2  -  0.0062134587205946445\n",
      "impoundment_amplified_no_streams  -  0.006077824858948588\n",
      "slope_min_2  -  0.006006758660078049\n",
      "skyview_max_6  -  0.005275094648823142\n",
      "impundment_std_4  -  0.0052372433710843325\n",
      "skyview_median_6  -  0.00509973824955523\n",
      "skyview_std_6  -  0.004975317278876901\n",
      "skyview_max_2  -  0.004956685123033822\n",
      "impundment_max_2  -  0.004777819383889437\n",
      "skyview_max_4  -  0.00456158840097487\n",
      "hpmf_mean_2  -  0.004338468424975872\n",
      "slope_std_6  -  0.004201444215141237\n",
      "slope_mean_6  -  0.004172111512161791\n",
      "slope_min_6  -  0.004134758608415723\n",
      "impundment_median_6  -  0.0038440536009147763\n",
      "skyview_std_4  -  0.003729183110408485\n",
      "slope_std_4  -  0.003684453433379531\n",
      "slope_median_6  -  0.0035335030406713486\n",
      "skyview_median_4  -  0.003240520949475467\n",
      "hpmf_min_6  -  0.0030919823329895735\n",
      "impundment_max_4  -  0.00300125393550843\n",
      "impundment_max_6  -  0.0029607811011373997\n",
      "conic_mean_no_streams  -  0.002956993062980473\n",
      "impundment_raw  -  0.0029143670108169317\n",
      "slope_mean_4  -  0.0029001968796364963\n",
      "impundment_mean_6  -  0.0028262458508834243\n",
      "skyview_mean_4  -  0.0028057656600140035\n",
      "skyview_mean_6  -  0.0027623747009783983\n",
      "hpmf_filter_no_streams  -  0.002659974619746208\n",
      "skyview_min_6  -  0.0026406466495245695\n",
      "slope_min_4  -  0.0026322873309254646\n",
      "impundment_std_6  -  0.0025763262528926134\n",
      "hpmf_max_6  -  0.002444017678499222\n",
      "slope_std_2  -  0.00235922634601593\n",
      "slope_median_2  -  0.002355976263061166\n",
      "hpmf_raw  -  0.0023545968579128385\n",
      "hpmf_filter  -  0.002268479496706277\n",
      "hpmf_gabor_no_streams  -  0.0022639973904006183\n",
      "conic_mean  -  0.0022544614621438086\n",
      "hpmf_std_2  -  0.002245105104520917\n",
      "slope_raw  -  0.002199303184170276\n",
      "skyview_std_2  -  0.0021575497230514884\n",
      "hpmf_std_6  -  0.0021112147951498628\n",
      "hpmf_max_2  -  0.002045385306701064\n",
      "hpmf_max_4  -  0.0019367504282854497\n",
      "slope_mean_2  -  0.0018645129166543484\n",
      "slope_max_4  -  0.0018290854059159756\n",
      "skyview_min_4  -  0.0017831145087257028\n",
      "hpmf_mean_3  -  0.0017684180638752878\n",
      "skyview_mean_3  -  0.0017495307547505945\n",
      "skyview_min_2  -  0.0016699801781214774\n",
      "slope_max_2  -  0.0016647171578370035\n",
      "hpmf_std_4  -  0.0016535117174498737\n",
      "impundment_min_4  -  0.001572105655213818\n",
      "impundment_std_2  -  0.0015674334717914462\n",
      "impundment_min_2  -  0.001557628100272268\n",
      "skyview_median_2  -  0.0015343176200985909\n",
      "slope_median_4  -  0.0014828650746494532\n",
      "DEM_ditch_detection  -  0.0012620275374501944\n",
      "slope_mean_3  -  0.0011848782887682319\n",
      "skyview_mean_2  -  0.0008149552159011364\n",
      "skyview_raw  -  0.0005950490449322388\n",
      "impundment_min_6  -  0.0\n",
      "\n",
      "\n",
      "Amount of features used:   81\n",
      "Cohen's kappa score         0.3828445848991844\n",
      "Accuracy score              0.9479871729235597\n",
      "Recall score                0.7534929677909309\n",
      "Precision score             0.2759687403111015\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Features used in experiment:\n",
      "['impundment_mean_3', 'hpmf_mean_4', 'hpmf_median_4', 'DEM_ditch_detection_no_streams', 'hpmf_min_2', 'impundment_mean_4', 'impundment_median_4', 'impundment_mean_2', 'hpmf_gabor', 'skyview_gabor', 'hpmf_min_4', 'slope_non_ditch', 'impundment_median_2', 'skyview_gabor_no_streams', 'impundment_amplified', 'hpmf_median_6', 'hpmf_mean_6', 'skyview_non_ditch', 'hpmf_median_2', 'impoundment_amplified_no_streams', 'slope_min_2', 'skyview_max_6', 'impundment_std_4', 'skyview_median_6', 'skyview_std_6', 'skyview_max_2', 'impundment_max_2', 'skyview_max_4', 'hpmf_mean_2', 'slope_std_6', 'slope_mean_6', 'slope_min_6', 'impundment_median_6', 'skyview_std_4', 'slope_std_4', 'slope_median_6', 'skyview_median_4', 'hpmf_min_6', 'impundment_max_4', 'impundment_max_6', 'conic_mean_no_streams', 'impundment_raw', 'slope_mean_4', 'impundment_mean_6', 'skyview_mean_4', 'skyview_mean_6', 'hpmf_filter_no_streams', 'skyview_min_6', 'slope_min_4', 'impundment_std_6']\n",
      "\n",
      "\n",
      "Amount of features X_train: 50, X_test: 50\n",
      "Amount of features X_train: 50, X_test: 50\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.3250857889652252\n",
      "hpmf_mean_4  -  0.10018923506140709\n",
      "impundment_mean_4  -  0.09521767497062683\n",
      "hpmf_median_4  -  0.07216311804950237\n",
      "hpmf_min_2  -  0.05339799262583256\n",
      "impundment_mean_2  -  0.049775583669543266\n",
      "DEM_ditch_detection_no_streams  -  0.028610064648091793\n",
      "impundment_median_4  -  0.023956457269378006\n",
      "skyview_gabor  -  0.016805225983262062\n",
      "impundment_median_2  -  0.01574273081496358\n",
      "slope_non_ditch  -  0.013561647851020098\n",
      "hpmf_mean_2  -  0.012138049176428467\n",
      "hpmf_median_6  -  0.011215596459805965\n",
      "impundment_amplified  -  0.01001563761383295\n",
      "skyview_gabor_no_streams  -  0.00972540769726038\n",
      "hpmf_min_4  -  0.009384678676724434\n",
      "hpmf_median_2  -  0.008755070390179753\n",
      "impoundment_amplified_no_streams  -  0.007692847168073058\n",
      "hpmf_gabor  -  0.007070786436088383\n",
      "skyview_max_6  -  0.006768450606614351\n",
      "skyview_non_ditch  -  0.006504376768134534\n",
      "impundment_max_2  -  0.005839669145643711\n",
      "impundment_std_4  -  0.005578688811510801\n",
      "slope_std_6  -  0.0055507729994133115\n",
      "hpmf_mean_6  -  0.005371382227167487\n",
      "skyview_max_4  -  0.005360145354643464\n",
      "skyview_median_6  -  0.005181378684937954\n",
      "slope_min_6  -  0.0051633554976433516\n",
      "slope_median_6  -  0.004972632508724928\n",
      "skyview_std_6  -  0.004866872215643525\n",
      "slope_std_4  -  0.004225643700920045\n",
      "slope_min_2  -  0.0041687797056511045\n",
      "skyview_median_4  -  0.0040864781476557255\n",
      "conic_mean_no_streams  -  0.004070188384503126\n",
      "skyview_mean_6  -  0.003919858834706247\n",
      "impundment_mean_6  -  0.0038845554227009416\n",
      "slope_mean_4  -  0.0036389591405168176\n",
      "skyview_std_4  -  0.0036180977476760745\n",
      "hpmf_filter_no_streams  -  0.003613582579419017\n",
      "impundment_max_4  -  0.003585106460377574\n",
      "skyview_max_2  -  0.0034541935892775655\n",
      "slope_mean_6  -  0.003372844774276018\n",
      "impundment_max_6  -  0.0033443140564486384\n",
      "hpmf_min_6  -  0.003210802678950131\n",
      "impundment_std_6  -  0.0031977606704458594\n",
      "impundment_raw  -  0.003056370187550783\n",
      "skyview_min_6  -  0.0027116963174194098\n",
      "impundment_median_6  -  0.0025773923844099045\n",
      "slope_min_4  -  0.0024844707222655416\n",
      "skyview_mean_4  -  0.0021175300935283303\n",
      "\n",
      "\n",
      "Amount of features used:   50\n",
      "Cohen's kappa score         0.3920184315317292\n",
      "Accuracy score              0.9504458020361328\n",
      "Recall score                0.7438816923030859\n",
      "Precision score             0.2854457033991778\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Features used in experiment:\n",
      "['impundment_mean_3', 'hpmf_mean_4', 'impundment_mean_4', 'hpmf_median_4', 'hpmf_min_2', 'impundment_mean_2', 'DEM_ditch_detection_no_streams', 'impundment_median_4', 'skyview_gabor', 'impundment_median_2', 'slope_non_ditch', 'hpmf_mean_2', 'hpmf_median_6', 'impundment_amplified', 'skyview_gabor_no_streams', 'hpmf_min_4', 'hpmf_median_2', 'impoundment_amplified_no_streams', 'hpmf_gabor', 'skyview_max_6', 'skyview_non_ditch', 'impundment_max_2', 'impundment_std_4', 'slope_std_6', 'hpmf_mean_6', 'skyview_max_4', 'skyview_median_6', 'slope_min_6', 'slope_median_6', 'skyview_std_6', 'slope_std_4', 'slope_min_2', 'skyview_median_4', 'conic_mean_no_streams', 'skyview_mean_6']\n",
      "\n",
      "\n",
      "Amount of features X_train: 35, X_test: 35\n",
      "Amount of features X_train: 35, X_test: 35\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.5461171865463257\n",
      "hpmf_mean_4  -  0.06937212310731411\n",
      "hpmf_min_2  -  0.046093680895864964\n",
      "hpmf_median_4  -  0.04386947490274906\n",
      "impundment_mean_4  -  0.04101790860295296\n",
      "impundment_mean_2  -  0.03546459972858429\n",
      "hpmf_gabor  -  0.017825331771746278\n",
      "skyview_gabor  -  0.017392511013895273\n",
      "DEM_ditch_detection_no_streams  -  0.012804910074919462\n",
      "slope_non_ditch  -  0.012761487858369946\n",
      "impundment_median_4  -  0.011829645838588476\n",
      "impundment_median_2  -  0.010467114392668009\n",
      "impundment_amplified  -  0.009666454512625933\n",
      "skyview_gabor_no_streams  -  0.009039255790412426\n",
      "hpmf_mean_2  -  0.008926108479499817\n",
      "hpmf_median_6  -  0.00830512074753642\n",
      "impoundment_amplified_no_streams  -  0.008128544548526406\n",
      "hpmf_median_2  -  0.007443887181580067\n",
      "skyview_non_ditch  -  0.0069097563391551375\n",
      "slope_min_2  -  0.00643650209531188\n",
      "skyview_max_4  -  0.006199672352522612\n",
      "skyview_max_6  -  0.005927755031734705\n",
      "hpmf_min_4  -  0.0054832398891448975\n",
      "impundment_max_2  -  0.0053727529011666775\n",
      "impundment_std_4  -  0.005128249176777899\n",
      "slope_median_6  -  0.005044011166319251\n",
      "skyview_median_6  -  0.004897713661193848\n",
      "skyview_std_6  -  0.004721212200820446\n",
      "hpmf_mean_6  -  0.004700805293396115\n",
      "slope_min_6  -  0.0046270196326076984\n",
      "slope_std_6  -  0.004580890410579741\n",
      "skyview_mean_6  -  0.004126052721403539\n",
      "conic_mean_no_streams  -  0.0035047702258452773\n",
      "slope_std_4  -  0.0033357832580804825\n",
      "skyview_median_4  -  0.0024784666020423174\n",
      "\n",
      "\n",
      "Amount of features used:   35\n",
      "Cohen's kappa score         0.3964734234887126\n",
      "Accuracy score              0.9509654056091715\n",
      "Recall score                0.7491732016625792\n",
      "Precision score             0.2887646673717077\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Features used in experiment:\n",
      "['impundment_mean_3', 'hpmf_mean_4', 'hpmf_min_2', 'hpmf_median_4', 'impundment_mean_4', 'impundment_mean_2', 'hpmf_gabor', 'skyview_gabor', 'DEM_ditch_detection_no_streams', 'slope_non_ditch', 'impundment_median_4', 'impundment_median_2', 'impundment_amplified', 'skyview_gabor_no_streams', 'hpmf_mean_2', 'hpmf_median_6', 'impoundment_amplified_no_streams', 'hpmf_median_2', 'skyview_non_ditch', 'slope_min_2', 'skyview_max_4', 'skyview_max_6', 'hpmf_min_4', 'impundment_max_2', 'impundment_std_4']\n",
      "\n",
      "\n",
      "Amount of features X_train: 25, X_test: 25\n",
      "Amount of features X_train: 25, X_test: 25\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.5007980316877365\n",
      "hpmf_mean_4  -  0.059894234873354435\n",
      "hpmf_median_4  -  0.055119337514042854\n",
      "impundment_mean_4  -  0.05446925200521946\n",
      "impundment_median_4  -  0.04432815150357783\n",
      "impundment_mean_2  -  0.039153847843408585\n",
      "hpmf_min_2  -  0.03567676991224289\n",
      "DEM_ditch_detection_no_streams  -  0.021785965654999018\n",
      "skyview_gabor  -  0.020975722931325436\n",
      "hpmf_mean_2  -  0.016812444664537907\n",
      "slope_non_ditch  -  0.016223351005464792\n",
      "hpmf_median_6  -  0.013796409126371145\n",
      "hpmf_median_2  -  0.013187645468860865\n",
      "impundment_amplified  -  0.012745196931064129\n",
      "skyview_gabor_no_streams  -  0.011652922723442316\n",
      "impundment_median_2  -  0.010589364916086197\n",
      "skyview_non_ditch  -  0.009941821452230215\n",
      "impoundment_amplified_no_streams  -  0.009558043675497174\n",
      "hpmf_min_4  -  0.008642523549497128\n",
      "hpmf_gabor  -  0.008387431036680937\n",
      "skyview_max_6  -  0.008218820672482252\n",
      "skyview_max_4  -  0.0074795265682041645\n",
      "impundment_std_4  -  0.0073095031548291445\n",
      "impundment_max_2  -  0.00690834317356348\n",
      "slope_min_2  -  0.006345313740894198\n",
      "\n",
      "\n",
      "Amount of features used:   25\n",
      "Cohen's kappa score         0.379890462280711\n",
      "Accuracy score              0.9483339573670363\n",
      "Recall score                0.7393632223767697\n",
      "Precision score             0.27513514772808995\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Features used in experiment:\n",
      "['impundment_mean_3', 'hpmf_mean_4', 'hpmf_median_4', 'impundment_mean_4', 'impundment_median_4', 'impundment_mean_2', 'hpmf_min_2', 'DEM_ditch_detection_no_streams', 'skyview_gabor', 'hpmf_mean_2', 'slope_non_ditch', 'hpmf_median_6', 'hpmf_median_2', 'impundment_amplified', 'skyview_gabor_no_streams', 'impundment_median_2', 'skyview_non_ditch', 'impoundment_amplified_no_streams', 'hpmf_min_4', 'hpmf_gabor']\n",
      "\n",
      "\n",
      "Amount of features X_train: 20, X_test: 20\n",
      "Amount of features X_train: 20, X_test: 20\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.28496165573596954\n",
      "impundment_median_4  -  0.14910253626294434\n",
      "impundment_mean_4  -  0.12306501157581806\n",
      "hpmf_mean_4  -  0.08149832114577293\n",
      "hpmf_median_4  -  0.06588636338710785\n",
      "hpmf_min_2  -  0.06073077581822872\n",
      "impundment_mean_2  -  0.04830809123814106\n",
      "skyview_gabor  -  0.02803292963653803\n",
      "DEM_ditch_detection_no_streams  -  0.0234520030207932\n",
      "slope_non_ditch  -  0.02003552159294486\n",
      "impundment_amplified  -  0.01675051311030984\n",
      "impoundment_amplified_no_streams  -  0.013677860144525766\n",
      "skyview_gabor_no_streams  -  0.013600422535091639\n",
      "hpmf_median_2  -  0.012881690636277199\n",
      "skyview_non_ditch  -  0.012714925920590758\n",
      "hpmf_gabor  -  0.011392629006877542\n",
      "hpmf_median_6  -  0.011162396986037493\n",
      "hpmf_min_4  -  0.01026324974372983\n",
      "impundment_median_2  -  0.009162652771919966\n",
      "hpmf_mean_2  -  0.003320449497550726\n",
      "\n",
      "\n",
      "Amount of features used:   20\n",
      "Cohen's kappa score         0.3003554925407471\n",
      "Accuracy score              0.9280312118734511\n",
      "Recall score                0.7437210960828132\n",
      "Precision score             0.2086840627971542\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Features used in experiment:\n",
      "['impundment_mean_3', 'impundment_median_4', 'impundment_mean_4', 'hpmf_mean_4', 'hpmf_median_4', 'hpmf_min_2', 'impundment_mean_2', 'skyview_gabor', 'DEM_ditch_detection_no_streams', 'slope_non_ditch', 'impundment_amplified', 'impoundment_amplified_no_streams', 'skyview_gabor_no_streams', 'hpmf_median_2', 'skyview_non_ditch']\n",
      "\n",
      "\n",
      "Amount of features X_train: 15, X_test: 15\n",
      "Amount of features X_train: 15, X_test: 15\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.5564840734004974\n",
      "hpmf_mean_4  -  0.07026596739888191\n",
      "impundment_median_4  -  0.05309335049241781\n",
      "hpmf_median_4  -  0.04990003630518913\n",
      "impundment_mean_4  -  0.039939599111676216\n",
      "hpmf_min_2  -  0.0356628717854619\n",
      "impundment_mean_2  -  0.032978758215904236\n",
      "hpmf_median_2  -  0.03015240002423525\n",
      "skyview_gabor  -  0.02545601688325405\n",
      "slope_non_ditch  -  0.02297361521050334\n",
      "impundment_amplified  -  0.01987079344689846\n",
      "skyview_gabor_no_streams  -  0.01895121857523918\n",
      "DEM_ditch_detection_no_streams  -  0.01563155511394143\n",
      "impoundment_amplified_no_streams  -  0.015266701113432646\n",
      "skyview_non_ditch  -  0.01337305549532175\n",
      "\n",
      "\n",
      "Amount of features used:   15\n",
      "Cohen's kappa score         0.2912849401848261\n",
      "Accuracy score              0.9248515054494698\n",
      "Recall score                0.7468404735138725\n",
      "Precision score             0.2015207980480668\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "Features used in experiment:\n",
      "['impundment_mean_3', 'hpmf_mean_4', 'impundment_median_4', 'hpmf_median_4', 'impundment_mean_4', 'hpmf_min_2', 'impundment_mean_2', 'hpmf_median_2', 'skyview_gabor', 'slope_non_ditch']\n",
      "\n",
      "\n",
      "Amount of features X_train: 10, X_test: 10\n",
      "Amount of features X_train: 10, X_test: 10\n",
      "\n",
      "\n",
      "Importances for experiment:\n",
      "impundment_mean_3  -  0.5571074187755585\n",
      "hpmf_median_4  -  0.1113474890589714\n",
      "impundment_median_4  -  0.06281379563733935\n",
      "hpmf_mean_4  -  0.05193728767335415\n",
      "impundment_mean_4  -  0.0449567511677742\n",
      "impundment_mean_2  -  0.0440783966332674\n",
      "skyview_gabor  -  0.034466211684048176\n",
      "slope_non_ditch  -  0.03164461860433221\n",
      "hpmf_min_2  -  0.031611492857337\n",
      "hpmf_median_2  -  0.030036556534469128\n",
      "\n",
      "\n",
      "Amount of features used:   10\n",
      "Cohen's kappa score         0.3005074306258476\n",
      "Accuracy score              0.9305860567947082\n",
      "Recall score                0.7169314689654609\n",
      "Precision score             0.21079577331213\n",
      "\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_important_features = zone_4.columns.tolist()[1:]\n",
    "for num_features in [81, 50, 35, 25, 20, 15, 10]:\n",
    "    \n",
    "    most_important_features = most_important_features[:num_features]\n",
    "    print(f\"Features used in experiment:\\n{most_important_features}\")\n",
    "    print(\"\\n\")\n",
    "    feature_importances = {i:0 for i in most_important_features}\n",
    "    y_test_all = []\n",
    "    pred_all = []\n",
    "    \n",
    "    \n",
    "    for (training_dataset, test_dataset) in experiment_arr:\n",
    "        X_train = training_dataset.filter(items=most_important_features).loc[:, training_dataset.filter(items=most_important_features).columns != \"label_3m\"]\n",
    "        y_train = training_dataset[\"label_3m\"]\n",
    "        training_dataset = None\n",
    "\n",
    "        clf = xgboost.XGBClassifier(tree_method=\"gpu_hist\",\n",
    "                                    colsample_bytree = 0.9125599,\n",
    "                                    gamma = 0.4130997,\n",
    "                                    learning_rate = 0.2495447,\n",
    "                                    max_depth = 3,\n",
    "                                    min_child_weight=0.347961,\n",
    "                                    n_estimators=155,\n",
    "                                    reg_alpha=0.000689,\n",
    "                                    scale_pos_weight=1.0,\n",
    "                                    subsample=0.426999)\n",
    "        \n",
    "        \n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = test_dataset.filter(items=most_important_features).loc[:, test_dataset.filter(items=most_important_features).columns != \"label_3m\"]\n",
    "        y_test = test_dataset[\"label_3m\"]\n",
    "        \n",
    "        print(f\"Amount of features X_train: {len(X_train.columns)}, X_test: {len(X_test.columns)}\")\n",
    "\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        for i, pred_var in enumerate(pred):\n",
    "            y_test_all.append(y_test[i])\n",
    "            pred_all.append(pred_var)\n",
    "\n",
    "        importances = clf.feature_importances_\n",
    "\n",
    "        \n",
    "        for i, importance in enumerate(importances):\n",
    "            feature_importances[most_important_features[i]] += importance\n",
    "        \n",
    "    for importance_name in most_important_features:\n",
    "        feature_importances[importance_name] /= 2\n",
    "    \n",
    "    \n",
    "    \n",
    "    most_important_features = list(dict(sorted(feature_importances.items(),\n",
    "                                               key=operator.itemgetter(1),reverse=True)).keys())\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Importances for experiment:\")\n",
    "    for key in most_important_features:\n",
    "        print(key, \" - \", feature_importances[key])\n",
    "    print(\"\\n\")\n",
    "    print(f\"Amount of features used:   {num_features}\")\n",
    "    print(\"Cohen's kappa score        \", cohen_kappa_score(y_test_all, pred_all))\n",
    "    print(\"Accuracy score             \", accuracy_score(y_test_all, pred_all))\n",
    "    print(\"Recall score               \", recall_score(y_test_all, pred_all))\n",
    "    print(\"Precision score            \", precision_score(y_test_all, pred_all))\n",
    "    print(\"\\n------------------------------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
