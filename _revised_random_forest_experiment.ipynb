{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score,confusion_matrix, cohen_kappa_score, precision_score\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score, f1_score, roc_auc_score, roc_curve\n",
    "import pandas as pd\n",
    "import math\n",
    "from joblib import dump, load\n",
    "import random\n",
    "import pickle\n",
    "import scipy.stats\n",
    "from PIL import Image\n",
    "import scipy.stats as stats\n",
    "\n",
    "from Functions import post_processing\n",
    "from Functions import general_functions\n",
    "from Functions import feature_creation\n",
    "\n",
    "from skimage.restoration import denoise_bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=NumbaPerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads all zones with their features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [f\"../zones_features_final/zone_{i}.pickle\" for i in range(11, 22)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following feature set was identified as the optimal in a tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['impundment_mean_3', 'impundment_mean_4', 'hpmf_mean_4', 'impundment_mean_2',\n",
    "                           'impundment_amplified', 'hpmf_median_4', 'impoundment_amplified_no_streams', 'hpmf_mean_3',\n",
    "                           'skyview_max_6', 'slope_std_6', 'impundment_median_4', 'hpmf_min_2', 'hpmf_mean_6',\n",
    "                           'skyview_max_4', 'slope_min_6', 'skyview_gabor', 'hpmf_min_4', 'skyview_gabor_no_streams',\n",
    "                           'impundment_max_6', 'skyview_non_ditch', 'skyview_median_6', 'impundment_std_4', 'skyview_min_6',\n",
    "                           'slope_min_4', 'slope_median_6', 'slope_std_4', 'impundment_median_2', 'skyview_max_2',\n",
    "                           'impundment_median_6', 'hpmf_std_6', 'hpmf_gabor_no_streams', 'skyview_std_6', 'hpmf_filter',\n",
    "                           'impundment_mean_6', 'slope_mean_6', 'slope_min_2', 'skyview_median_2', 'hpmf_filter_no_streams',\n",
    "                           'impundment_std_6', 'slope_non_ditch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following parameters were identified as the optimal in a tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion': 'gini',\n",
    "   'max_depth': None,\n",
    "   'min_samples_split': 10,\n",
    "   'class_weight': None,\n",
    "   'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.empty((11,53), dtype=object)\n",
    "\n",
    "predictions = np.empty((11, 3, 7852140))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performs 11 sub-experiments\n",
    "Trains with 10 zones for each sub-experiment, and evaluates on one zone.\n",
    "Each zone is evaluated once. Similar to cross validation but without randomly assigned subsets of data.\n",
    "All of these 11 zones were hold-out data, which means that they had never before been used in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\post_processing.py:117: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"custom_remove_noise\" failed type inference due to: \u001b[1mUntyped global name 'd_gf':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 122:\u001b[0m\n",
      "\u001b[1mdef custom_remove_noise(arr, radius, threshold, selfThreshold):\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "\u001b[1m    max_arr = d_gf(da.from_array(arr, chunks=(800, 800)), np.nanmax,\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"custom_remove_noise\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 118:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef custom_remove_noise(arr, radius, threshold, selfThreshold):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 118:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef custom_remove_noise(arr, radius, threshold, selfThreshold):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\general_functions.py:51: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"create_circular_mask\" failed type inference due to: \u001b[1m\u001b[1mUse of unsupported NumPy function 'numpy.ogrid' or unsupported use of the function.\n",
      "\u001b[1m\n",
      "File \"Functions\\general_functions.py\", line 57:\u001b[0m\n",
      "\u001b[1mdef create_circular_mask(radius):\n",
      "    <source elided>\n",
      "    kernel = np.zeros((2*radius+1, 2*radius+1))\n",
      "\u001b[1m    y, x = np.ogrid[-radius:radius+1, -radius:radius+1]\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of get attribute at E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\general_functions.py (57)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Functions\\general_functions.py\", line 57:\u001b[0m\n",
      "\u001b[1mdef create_circular_mask(radius):\n",
      "    <source elided>\n",
      "    kernel = np.zeros((2*radius+1, 2*radius+1))\n",
      "\u001b[1m    y, x = np.ogrid[-radius:radius+1, -radius:radius+1]\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"create_circular_mask\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"Functions\\general_functions.py\", line 52:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef create_circular_mask(radius):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Functions\\general_functions.py\", line 52:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef create_circular_mask(radius):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\post_processing.py:324: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"conic_proba_post_processing\" failed type inference due to: \u001b[1mUntyped global name 'd_gf':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 330:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    masks = []\n",
      "\u001b[1m    maxArr = d_gf(da.from_array(arr,chunks = (800,800)), np.nanmax, footprint=general_functions.create_circular_mask(5))\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\post_processing.py:324: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"conic_proba_post_processing\" failed type inference due to: \u001b[1mUntyped global name 'd_gf':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 330:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    masks = []\n",
      "\u001b[1m    maxArr = d_gf(da.from_array(arr,chunks = (800,800)), np.nanmax, footprint=general_functions.create_circular_mask(5))\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"conic_proba_post_processing\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 329:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "\u001b[1m    masks = []\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 329:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    \"\"\"\n",
      "\u001b[1m    masks = []\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\post_processing.py:324: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"conic_proba_post_processing\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\post_processing.py (331)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 331:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    maxArr = d_gf(da.from_array(arr,chunks = (800,800)), np.nanmax, footprint=general_functions.create_circular_mask(5))\n",
      "\u001b[1m    for i in range(0, 8):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"conic_proba_post_processing\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 331:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    maxArr = d_gf(da.from_array(arr,chunks = (800,800)), np.nanmax, footprint=general_functions.create_circular_mask(5))\n",
      "\u001b[1m    for i in range(0, 8):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 331:\u001b[0m\n",
      "\u001b[1mdef conic_proba_post_processing(arr, maskRadius, threshold):\n",
      "    <source elided>\n",
      "    maxArr = d_gf(da.from_array(arr,chunks = (800,800)), np.nanmax, footprint=general_functions.create_circular_mask(5))\n",
      "\u001b[1m    for i in range(0, 8):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "E:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\post_processing.py:156: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"_get_cluster_array\" failed type inference due to: \u001b[1mUntyped global name 'deque':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'type'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 166:\u001b[0m\n",
      "\u001b[1mdef _get_cluster_array(arr, index, zoneSize):\n",
      "    <source elided>\n",
      "    j = index[1]\n",
      "\u001b[1m    FIFOQueue = deque([(i, j)])\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:177: NumbaWarning: \u001b[1mFunction \"_get_cluster_array\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 157:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef _get_cluster_array(arr, index, zoneSize):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "C:\\Users\\Jonatan\\.conda\\envs\\pytorch\\lib\\site-packages\\numba\\core\\object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"Functions\\post_processing.py\", line 157:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef _get_cluster_array(arr, index, zoneSize):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.37 GiB for an array with shape (81, 7852140) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f078de3f5412>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtraining_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneral_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myield_training_test_zones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtraining_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneral_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_balanced_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"label_3m\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures_to_use\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Skola\\Examensarbete\\Ditch-article-revision\\Functions\\general_functions.py\u001b[0m in \u001b[0;36mcreate_balanced_dataset\u001b[1;34m(list_of_zones)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m         \u001b[0mzone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[0mframes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4108\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4109\u001b[0m         \"\"\"\n\u001b[1;32m-> 4110\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4111\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4112\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3946\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3947\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3949\u001b[0m         \u001b[1;31m# Case for non-unique axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mkind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3974\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"axis\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3975\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3976\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3978\u001b[0m     def drop(\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4490\u001b[0m             )\n\u001b[0;32m   4491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4492\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4494\u001b[0m         \u001b[1;31m# if all axes that are requested to reindex are equal, then only copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5239\u001b[0m         \"\"\"\n\u001b[0;32m   5240\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5241\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5249\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5252\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1910\u001b[0m     \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1911\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1912\u001b[1;33m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[0;32m   1913\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_can_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         )\n",
      "\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   3338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3339\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3340\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3341\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.37 GiB for an array with shape (81, 7852140) and data type float32"
     ]
    }
   ],
   "source": [
    "for i, (training_files, test_file) in enumerate(general_functions.yield_training_test_zones(file_list)):\n",
    "    training_dataset = general_functions.create_balanced_dataset(training_files)\n",
    "    \n",
    "    X_train = training_dataset.loc[:, training_dataset.columns != \"label_3m\"]\n",
    "    X_train = X_train.filter(items=features_to_use)\n",
    "    y_train = training_dataset[\"label_3m\"]\n",
    "    training_dataset = None\n",
    "    \n",
    "    clf = RandomForestClassifier(**params, n_jobs=-1, random_state=42)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    test_dataset = pd.read_pickle(test_file)\n",
    "    X_test = test_dataset.loc[:, test_dataset.columns != \"label_3m\"]\n",
    "    X_test = X_test.filter(items=features_to_use)\n",
    "\n",
    "    y_test = np.array(test_dataset[\"label_3m\"])    \n",
    "    \n",
    "    proba = clf.predict_proba(X_test)[:,1:].reshape(2997,2620)\n",
    "    \n",
    "    proba_post_process = post_processing.proba_post_process(proba, 6, 0.4)\n",
    "    \n",
    "    labels_grid = post_processing.raster_to_zones(y_test.reshape(2997, 2620), 6, 4)\n",
    "    \n",
    "    experiment_preds = (proba.reshape(-1), proba_post_process.reshape(-1), labels_grid.reshape(-1))\n",
    "    for j in range(3):\n",
    "        predictions[i][j] = experiment_preds[j]\n",
    "\n",
    "    experiment_importances = clf.feature_importances_\n",
    "    feature_names = features_to_use\n",
    "    tuple_features = [(feature_names[i], importance) for i, importance in enumerate(experiment_importances)]\n",
    "    for j in range(len(feature_names)):\n",
    "        importances[i][j] = (tuple_features[j][0], tuple_features[j][1]*100)\n",
    "\n",
    "np.save(\"../revised_results/predictions.npy\", predictions)\n",
    "np.save(\"../revised_results/feature_importances_11_experiments.npy\", importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads saved experiment results from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load(\"../revised_results/predictions.npy\")\n",
    "prediction2d = np.concatenate(predictions, axis= 1)\n",
    "y_pred_all = prediction2d[1]\n",
    "y_test_all = prediction2d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(11, 3, 2997, 2620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying evaluation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(predictions.shape[0]):\n",
    "    pred = predictions[i, 1]\n",
    "    labels = predictions[i, 2]\n",
    "    new_labels = labels.copy()\n",
    "    false_positives = np.zeros(pred.shape)\n",
    "    false_negatives = np.zeros(pred.shape)\n",
    "    for j in range(pred.shape[0]):\n",
    "        for k in range(pred.shape[1]):\n",
    "            if pred[j, k] == 1 and labels[j, k] == 0:\n",
    "                false_positives[j, k] = 1\n",
    "            elif pred[j, k] == 0 and labels[j, k] == 1:\n",
    "                false_negatives[j, k] = 1\n",
    "    for j in range(0, len(pred) - 6, 6):\n",
    "        for k in range(0, len(pred[i]) - 6, 6):\n",
    "            if false_positives[j, k] == 1:\n",
    "                if labels[j+6, k] == 1 or labels[j-6, k] == 1 or labels[j, k+6] == 1 or labels[j, k-6] == 1:\n",
    "                    for l in range(j, j+6):\n",
    "                        for m in range(k, k+6):\n",
    "                            new_labels[l, m] = 1\n",
    "            if false_negatives[j, k] == 1:\n",
    "                if pred[j+6, k] == 1 or pred[j-6, k] == 1 or pred[j, k+6] == 1 or pred[j, k-6] == 1:\n",
    "                    for l in range(j, j+6):\n",
    "                        for m in range(k, k+6):\n",
    "                            new_labels[l, m] = 0\n",
    "                            \n",
    "    np.save(f\"../revised_results/new_labels_zone_{i+1}.npy\", new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load(\"../revised_results/predictions.npy\")\n",
    "prediction2d = np.concatenate(predictions, axis= 1)\n",
    "y_pred_all = prediction2d[1]\n",
    "y_test_all = np.load(\"../revised_results/new_labels_zone_1.npy\").reshape(-1)\n",
    "for i in range (2, 12):\n",
    "    y_test_all = np.append(y_test_all, np.load(f\"../revised_results/new_labels_zone_{i}.npy\").reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score             \", accuracy_score(y_test_all, y_pred_all))\n",
    "print(\"Recall score               \", recall_score(y_test_all, y_pred_all))\n",
    "print(\"Precision score            \", precision_score(y_test_all, y_pred_all))\n",
    "precision, recall, threshholds = precision_recall_curve(y_test_all,y_pred_all)\n",
    "auc_score = auc(recall, precision)\n",
    "print(\"Cohen's kappa score        \", cohen_kappa_score(y_test_all, y_pred_all))\n",
    "print(\"AUPRC score                \", auc_score)\n",
    "print(\"Confusion matrix\\n\", confusion_matrix(y_test_all, y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_zone = []\n",
    "for i, zone in enumerate(predictions):\n",
    "    proba, binary_prediction, old_labels = zone\n",
    "    labels_grid = np.load(f\"../revised_results/new_labels_zone_{i+1}.npy\").reshape(-1)\n",
    "    acc = accuracy_score(labels_grid, binary_prediction)\n",
    "    _recall = recall_score(labels_grid, binary_prediction)\n",
    "    _precision = precision_score(labels_grid, binary_prediction)\n",
    "    kappa = cohen_kappa_score(labels_grid, binary_prediction)\n",
    "    precision, recall, threshholds = precision_recall_curve(labels_grid, binary_prediction)\n",
    "    auc_score = auc(recall, precision)\n",
    "    metrics = (acc, _recall, _precision, kappa, auc_score)\n",
    "    metrics_per_zone.append(metrics)\n",
    "    print(f\"Zone {i+1}:\\nAccuracy: {metrics[0]}, Recall: {metrics[1]}, Precision: {metrics[2]}, Cohen's Kappa: {metrics[3]}, AUPRC: {metrics[4]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence = 0.95):\n",
    "    sample = np.array(data)\n",
    "    sample_size, sample_mean = len(sample), sample.mean()\n",
    "    z_critical = stats.norm.ppf(q = ((1+confidence) / 2.))  # Get the z-critical value*\n",
    "    margin_of_error = z_critical * (sample.std() / math.sqrt(sample_size))\n",
    "    return (sample_mean, sample_mean - margin_of_error, sample_mean + margin_of_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"accuracy\", \"recall\", \"precision\", \"Cohen's Kappa\", \"AUPRC\"]\n",
    "avg = 0\n",
    "for i in range(0, 5):\n",
    "    for interval in [0.90, 0.95, 0.99]:\n",
    "        conf_int = mean_confidence_interval([j[i] for j in metrics_per_zone], interval)\n",
    "        avg = conf_int[0]\n",
    "        print(f\"Confidence interval for {metric_names[i]} at {interval * 100}%: [{conf_int[1]}, {conf_int[2]}]\")\n",
    "    print(f\"Average for {metric_names[i]}: {avg}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(15,65), facecolor='w', edgecolor='k')\n",
    "ax = [plt.subplot(11,3,i+1) for i in range(33)]\n",
    "for a in ax:\n",
    "    a.set_xticklabels([])\n",
    "    a.set_yticklabels([])\n",
    "    a.tick_params(bottom=False, left=False)\n",
    "plt.subplots_adjust(wspace=0,hspace=0.1)\n",
    "\n",
    "for i, zone_pred in enumerate(predictions):\n",
    "    ax[i*3].title.set_text(f\"Raw probability zone {i+1}\")\n",
    "    ax[i*3].imshow(zone_pred[0].reshape(2997,2620))\n",
    "    ax[i*3+1].title.set_text(f\"Binary prediction zone {i+1}\")\n",
    "    ax[i*3+1].imshow(zone_pred[1].reshape(2997,2620))\n",
    "    ax[i*3+2].title.set_text(f\"Labels zone {i+1}\")\n",
    "    ax[i*3+2].imshow(np.load(f\"../revised_results/new_labels_zone_{i+1}.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(30,45), facecolor='w', edgecolor='k')\n",
    "ax = [plt.subplot(4,3,i+1) for i in range(11)]\n",
    "for a in ax:\n",
    "    a.set_xticklabels([])\n",
    "    a.set_yticklabels([])\n",
    "    a.tick_params(bottom=False, left=False)\n",
    "plt.subplots_adjust(wspace=0,hspace=0.1)\n",
    "\n",
    "for k, zone_pred in enumerate(predictions):\n",
    "    validation = np.load(f\"../revised_results/new_labels_zone_{k+1}.npy\")\n",
    "    pred = zone_pred[1].reshape(2997,2620)\n",
    "    displayImg = Image.new(\"RGB\", (2620, 2997), \"white\")\n",
    "    pixels = displayImg.load()\n",
    "    for i in range(displayImg.size[0]):\n",
    "        for j in range(displayImg.size[1]):\n",
    "            if validation[j][i] == 1 and pred[j][i] == 1:\n",
    "                pixels[i,j] = (0, 180, 0)\n",
    "            elif validation[j][i] == 1 and pred[j][i] == 0:\n",
    "                pixels[i,j] = (50, 150, 255)\n",
    "            elif validation[j][i] == 0 and pred[j][i] == 1:\n",
    "                pixels[i,j] = (255, 50, 50)\n",
    "    \n",
    "    ax[k].title.set_text(f\"Result graphics zone {k+1}\")\n",
    "    ax[k].imshow(displayImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
